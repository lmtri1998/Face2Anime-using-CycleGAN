# -*- coding: utf-8 -*-
"""CycleGAN Code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lCCWtCWl8KuZdtxVXTL_LQRuIUsnFfYI

#References

##Data
https://www.kaggle.com/sharmayush/person2anime/activity

##Model 
https://github.com/arnab39/cycleGAN-PyTorch/blob/master/model.py

https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix

https://arxiv.org/pdf/1703.10593.pdf

# Imports
"""

import torch.nn as nn
import torch
import itertools
import os
import shutil
import time

import torch.nn.functional as F
import torchvision.transforms as transforms
import torch
import torchvision
import numpy as np
import matplotlib.pyplot as plt



"""# Models

## Generator
"""
# GPU settings and training dataset size
# If you don't have GPU, set use_cuda = True
# However this entirely instance is optimized towards training with GPU
# We recommend running this entire notebook on Google Colab if you don't have a GPU

use_cuda = True
multiGPU = False
use_dropout = True
dataset_size = 3400
MAX_POOL = 50

# Scale-factor for number of parameters to train
    # Dr. Zhu suggests 64 in his paper

PM = 64


class ResnetBlock(nn.Module):
    def __init__(self, dim, use_dropout):
        super(ResnetBlock, self).__init__()
        self.model = self.buildBlock(dim, use_dropout)
    
    def buildBlock(self, dim, use_dropout, pm=PM):
        self.model = nn.Sequential(
            nn.ReflectionPad2d(1),
            nn.Conv2d(in_channels=pm * 4, out_channels=pm * 4, kernel_size=3, stride=1, padding=0, bias=True),
            nn.InstanceNorm2d(pm * 4),
            nn.ReLU(True),
            
            nn.Dropout(p=0.5),

            nn.ReflectionPad2d(1),
            nn.Conv2d(in_channels=pm * 4, out_channels=pm * 4, kernel_size=3, stride=1, padding=0, bias=True),
            nn.InstanceNorm2d(pm * 4)  
        )
        return self.model
        
    def forward(self, input):
        # Add skip connection
        out = input + self.model(input)
        return out

class Generator_Res(nn.Module):
    def __init__(self, inchannels = 3, outchannels = 3, pm=PM):
        super(Generator_Res, self).__init__()
        self.model = nn.Sequential(
            
            #Downsampling
            nn.ReflectionPad2d(3),

            nn.Conv2d(in_channels=inchannels, out_channels=pm*1, kernel_size=7, stride=1, padding=0, bias=True),
            nn.InstanceNorm2d(pm * 1),
            nn.ReLU(True),

            nn.Conv2d(in_channels=pm*1, out_channels=pm * 2, kernel_size=3, stride=2, padding=1, bias=True),
            nn.InstanceNorm2d(pm * 2),
            nn.ReLU(True),

            nn.Conv2d(in_channels=pm*2, out_channels=pm*4, kernel_size=3, stride=2, padding=1, bias=True),
            nn.InstanceNorm2d(pm * 4),
            nn.ReLU(True),

            #Resblocks # 1
            ResnetBlock(dim=64, use_dropout=use_dropout),
            #Resblocks # 2
            ResnetBlock(dim=64, use_dropout=use_dropout),
            #Resblocks # 3
            ResnetBlock(dim=64, use_dropout=use_dropout),
            #Resblocks # 4
            ResnetBlock(dim=64, use_dropout=use_dropout),
            #Resblocks # 5
            ResnetBlock(dim=64, use_dropout=use_dropout),
            #Resblocks # 6
            ResnetBlock(dim=64, use_dropout=use_dropout),
            
            #Upsampling
            nn.ConvTranspose2d(in_channels=pm * 4, out_channels=pm * 2, kernel_size=3, stride=2, padding=1,
                               output_padding=1),
            nn.InstanceNorm2d(pm * 2),
            nn.ReLU(True),

            nn.ConvTranspose2d(in_channels=pm * 2, out_channels=pm * 1, kernel_size=3, stride=2, padding=1,
                               output_padding=1),
            nn.InstanceNorm2d(pm * 1),
            nn.ReLU(True),

            nn.ReflectionPad2d(3),
            nn.Conv2d(pm, outchannels, 7),
            nn.Tanh()
        )

        if (multiGPU):
            self.model = nn.DataParallel(self.model)
            
    def forward(self, x):
        return self.model(x)

"""## Discriminator"""

class Discriminator_Patch(nn.Module):
    def __init__(self, inchannels = 3, outchannels=1, pm=PM):
        super(Discriminator_Patch, self).__init__()
        self.model = nn.Sequential(
            nn.Conv2d(in_channels=inchannels, out_channels=pm *1, kernel_size=4, stride=2, padding=1, bias=False),
            nn.LeakyReLU(0.2, True),

            nn.Conv2d(in_channels = pm * 1, out_channels=pm * 2, kernel_size=4, stride=2, padding=1, bias=False),
            nn.InstanceNorm2d(pm * 2),
            nn.LeakyReLU(0.2, True),

            nn.Conv2d(in_channels=pm * 2, out_channels=pm * 4, kernel_size=4, stride=2, padding=1, bias=False),
            nn.InstanceNorm2d(pm * 4),
            nn.LeakyReLU(0.2, True),

            nn.Conv2d(in_channels=pm * 4, out_channels=pm * 8, kernel_size=4, stride=1, padding=1, bias=False),
            nn.InstanceNorm2d(pm * 4),
            nn.LeakyReLU(0.2, True),

            nn.Conv2d(in_channels=pm * 8, out_channels=outchannels, kernel_size=4, stride=1, padding=1)
        )
        if (multiGPU):
            self.model = nn.DataParallel(self.model)

    def forward(self, x):
        return self.model(x)


"""# Rand pool Function"""
def Rand_pool(cur_list, cur_fake):
  if len(cur_list) < MAX_POOL:
    cur_list.append(cur_fake)
    out_fake = cur_fake
  else:
    if np.random.ranf() > 0.5:
      index = np.random.randint(0, MAX_POOL)
      out_fake = cur_list[index].copy()
      cur_list[index] = cur_fake
    else:
      out_fake = cur_fake
  return cur_list, out_fake


"""# Training Function"""
def train(LoaderA, LoaderB, Gen_A, Gen_B, Dis_A, Dis_B, G_lambda=10, G_idtcoeff=0.5, g_lr=0.05, d_lr=0.05, epochs=100):
    # Clear cache
    if use_cuda:
        torch.cuda.empty_cache()
    
    criterionMSE = nn.MSELoss()
    criterionL1 = nn.L1Loss()
    
    # Set-up the optimizer
    G_optimizer = torch.optim.Adam(itertools.chain(Gen_A.parameters(),Gen_B.parameters()), lr=g_lr, betas=(0.5, 0.999))
    D_optimizer = torch.optim.Adam(itertools.chain(Dis_A.parameters(), Dis_B.parameters()), lr=d_lr, betas=(0.5, 0.999))

    if use_cuda and torch.cuda.is_available():
        Gen_A = Gen_A.cuda()
        Gen_B = Gen_B.cuda()
        Dis_A = Dis_A.cuda()
        Dis_B = Dis_B.cuda()
        print("cuda training")
    else:
        print("cpu training")

    track_loss = []

    # Rand_pool_A = []
    # Rand_pool_B = []
    
    for epoch in range(epochs):
        
        epoch_start_time = time.time()
        
        # Learning rate decay for over 100 epochs
        if epoch > 100:
            g_lr *= 0.993
            d_lr *= 0.993
        
        for i, (_a_real, _b_real) in enumerate(zip(LoaderA, LoaderB)):

            #remove label from imagefolder
            a_real = _a_real[0] 
            b_real = _b_real[0]
            if use_cuda and torch.cuda.is_available():
                a_real=a_real.cuda()
                b_real=b_real.cuda()
                
            #A: faces
            #B: anime
            #Generators
            
            # -----------------------------
            # Anime Cycle: B -> A' -> B^ === b_real -> a_fake -> b-recon
            # -----------------------------
            
            G_optimizer.zero_grad()
            a_fake = Gen_B(b_real)
            a_dis_pred = Dis_B(a_fake)
            
            # Create a truth label
            label_1 = torch.ones(a_dis_pred.size())
            if use_cuda and torch.cuda.is_available():
                label_1 = label_1.cuda()
            # Generator MSE loss
            b_gen_loss = criterionMSE(a_dis_pred, label_1)
            
            b_recon = Gen_A(a_fake)
            b_cycle_loss = criterionL1(b_recon, b_real) * G_lambda
            
            b_idt = Gen_B(a_real)
            b_idt_losses = criterionL1(b_idt, a_real) * G_lambda * G_idtcoeff
            
            b_total_loss = b_gen_loss + b_cycle_loss + b_idt_losses
            b_total_loss.backward(retain_graph=True)
            G_optimizer.step()
            
            # -----------------------------
            # Selfie Cycle: A -> B' -> A^
            # -----------------------------
            
            G_optimizer.zero_grad()
            b_fake = Gen_A(a_real)
            b_dis_pred = Dis_A(b_fake)
            # Create a truth label
            label_1 = torch.ones(b_dis_pred.size())
            if use_cuda and torch.cuda.is_available():
                label_1 = label_1.cuda()
            a_gen_loss = criterionMSE(b_dis_pred, label_1)
            
            a_recon = Gen_B(b_fake)
            a_cycle_loss = criterionL1(a_recon, a_real) * G_lambda
            
            a_idt = Gen_A(b_real)
            a_idt_losses = criterionL1(a_idt, b_real) * G_lambda * G_idtcoeff
            
            a_total_loss = a_gen_loss + a_cycle_loss + a_idt_losses
            a_total_loss.backward(retain_graph=True)
            G_optimizer.step()
            
            # -----------------------------
            # B Discriminators
            # -----------------------------
            D_optimizer.zero_grad()
            
            # Real
            b_real_dis = Dis_B(a_real)
            
            dlabel_1 = torch.ones(b_real_dis.size())
            if use_cuda and torch.cuda.is_available():
                dlabel_1 = dlabel_1.cuda()
            
            b_dis_real_loss = criterionMSE(b_real_dis, dlabel_1)
            
            # Fake
            # Rand_pool_A, _a_fake = Rand_pool(Rand_pool_A, a_fake.cpu().data.numpy())
            # gen_a_fake = torch.Tensor(_a_fake)

            b_fake_dis = Dis_B(a_fake)
            dlabel_0 = torch.zeros(b_fake_dis.size())
            if use_cuda and torch.cuda.is_available():
                dlabel_0 = dlabel_0.cuda()
            
            b_dis_fake_loss = criterionMSE(b_fake_dis, dlabel_0)
            
            # Step optimizer and backprop
            b_dis_loss = (b_dis_real_loss + b_dis_fake_loss) * 0.5
            b_dis_loss.backward()
            D_optimizer.step()
            
            # -----------------------------
            # A Discriminators
            # -----------------------------
            D_optimizer.zero_grad()
            
            # Real
            a_real_dis = Dis_A(b_real)
            
            dlabel_1 = torch.ones(a_real_dis.size())
            if use_cuda and torch.cuda.is_available():
                dlabel_1 = dlabel_1.cuda()
            
            a_dis_real_loss = criterionMSE(a_real_dis, dlabel_1)
            
            # Fake
            # Rand_pool_B, _b_fake = Rand_pool(Rand_pool_B, b_fake.cpu().data.numpy())
            # gen_b_fake = torch.Tensor(_b_fake)
            a_fake_dis = Dis_A(b_fake)
            dlabel_0 = torch.zeros(a_fake_dis.size())
            if use_cuda and torch.cuda.is_available():
                dlabel_0 = dlabel_0.cuda()
            
            a_dis_fake_loss = criterionMSE(a_fake_dis, dlabel_0)
            
            # Step optimizer and backprop
            a_dis_loss = (a_dis_real_loss + a_dis_fake_loss) * 0.5
            a_dis_loss.backward()
            D_optimizer.step()
            
            if i % (dataset_size//(Batch_size*5)) == 0:
                print("Epoch", epoch, " Iteration ", i)
                print("A dis_loss: ", a_dis_loss.item())
                print("B dis_loss: ", b_dis_loss.item())
                print("A total_loss: ", a_total_loss.item())
                print("B total_loss: ", b_total_loss.item())
                
                # A
                filename = "face2anime_SelfieCycle" + '_epoch_%03d_%04d.png' % (epoch, i,)
                save_path = os.path.join('weeb_predictions/A/', filename)
                A_grid = torch.cat((b_real,a_fake,b_recon),dim=0)
                torchvision.utils.save_image(A_grid, save_path, nrow=3, normalize=True)
                
                # B
                filename = "face2anime_AnimeCycle" + '_epoch_%03d_%04d.png' % (epoch, i,)
                save_path = os.path.join('weeb_predictions/B/', filename)
                B_grid = torch.cat((a_real,b_fake,a_recon),dim=0)
                torchvision.utils.save_image(B_grid, save_path, nrow=3, normalize=True)
                

        # For each epoch
        # Saves 
        epoch_loss = {
            'a_gen_loss':a_gen_loss.item(),
            'b_gen_loss':b_gen_loss.item(),
            'a_cycle_loss':a_cycle_loss.item(),
            'b_cycle_loss':b_cycle_loss.item(),
            'a_idt_losses':a_idt_losses.item(),
            'b_idt_losses':b_idt_losses.item(),
            'a_dis_real_loss':a_dis_real_loss.item(),
            'a_dis_fake_loss':a_dis_fake_loss.item(),
            'b_dis_real_loss':b_dis_real_loss.item(),
            'b_dis_fake_loss':b_dis_fake_loss.item(),
            'a_dis_loss':a_dis_loss.item(),
            'b_dis_loss':b_dis_loss.item()
        }
        track_loss.append(epoch_loss)
  
        if epoch % 5 == 0:
            save_filename = f'{"face2anime"}_netG_{epoch}.pt'
            save_filepath = os.path.join('weeb_checkpoints/', save_filename) 
            torch.save({"epoch_loss":track_loss,
                        'Gen_A_state_dict':Gen_A.state_dict(),
                        'Gen_B_state_dict':Gen_B.state_dict(),
                        'Dis_A_state_dict': Dis_A.state_dict(),
                        'Dis_B_state_dict': Dis_B.state_dict(),
                        "G_optimizer":G_optimizer.state_dict(),
                        "D_optimizer":D_optimizer.state_dict()
                       }
                       , save_filepath)

        epoch_time = int(time.time() - epoch_start_time)
        print("This epoch took %.3d secs"%epoch_time)
        print("-------------------------------------")
    return Gen_A, Gen_B, track_loss




if __name__ == '__main__':
    # This code is to remove results from the previous run
    # DO NOT run this if you first run this code
    # shutil.rmtree("weeb_predictions")
    # shutil.rmtree("weeb_checkpoints")

    # Make diretories for checkpoints and predictions
    os.makedirs("weeb_predictions/A/", exist_ok=True)
    os.makedirs("weeb_predictions/A/", exist_ok=True)
    os.makedirs("weeb_predictions/B/", exist_ok=True)
    os.makedirs("weeb_checkpoints/", exist_ok=True)


    # Root directory, change this according to your local directory
    root = ''

    dir_A = root+'/datasets/face2anime/trainA'
    dir_B = root+'/datasets/face2anime/trainB'
    t_dir_A = root+'/datasets/face2anime/testA'
    t_dir_B = root+'/datasets/face2anime/testB'

    _transform = transforms.Compose(
        [
            transforms.RandomHorizontalFlip(),
            transforms.Resize((128,128)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
        ])

    SetA = torchvision.datasets.ImageFolder(root=dir_A, transform=_transform)
    SetB = torchvision.datasets.ImageFolder(root=dir_B, transform=_transform)
    testA = torchvision.datasets.ImageFolder(root=t_dir_A, transform=_transform)
    testB = torchvision.datasets.ImageFolder(root=t_dir_A, transform=_transform)
    #instance = ([3,128,128],0)

    A_Shuffle=True
    B_Shuffle=True

    # Change batch size here
    Batch_size= 1
    num_workers = 1

    LoaderA = torch.utils.data.DataLoader(SetA, batch_size=Batch_size,shuffle=A_Shuffle, num_workers=num_workers)
    LoaderB = torch.utils.data.DataLoader(SetB, batch_size=Batch_size,shuffle=B_Shuffle, num_workers=num_workers)

    # There isn't a point to randomly shuffle tht test sets
    # No shuffling for more convenient indexing
    LoadertestA = torch.utils.data.DataLoader(testA, batch_size=Batch_size, shuffle=False, num_workers=num_workers)
    LoadertestB = torch.utils.data.DataLoader(testB, batch_size=Batch_size, shuffle=False, num_workers=num_workers)

    """# Training"""

    # Initialize the Generators
    Gen_A = Generator_Res()
    Gen_B = Generator_Res()
    Dis_A = Discriminator_Patch()
    Dis_B = Discriminator_Patch()

    # Start Training
    women_generator, waifu_generator, track_loss = train(LoaderA, LoaderB, Gen_A, Gen_B, Dis_A, Dis_B, G_lambda=10, G_idtcoeff=0.5,
                                             g_lr=0.0002, d_lr=0.0002, epochs=100)